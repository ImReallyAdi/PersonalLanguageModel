<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Personal Language Model - Unified Interface</title>
    <script src="https://cdn.jsdelivr.net/pyodide/v0.24.1/full/pyodide.js"></script>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            padding: 20px;
        }
        
        .container {
            max-width: 900px;
            margin: 0 auto;
            background: white;
            border-radius: 15px;
            box-shadow: 0 10px 30px rgba(0,0,0,0.2);
            overflow: hidden;
        }
        
        .header {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 30px;
            text-align: center;
        }
        
        .header h1 {
            font-size: 2.5em;
            margin-bottom: 10px;
        }
        
        .header p {
            opacity: 0.9;
            font-size: 1.1em;
        }
        
        .backend-selector {
            padding: 20px;
            background: #f8f9fa;
            border-bottom: 1px solid #e9ecef;
        }
        
        .backend-options {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 20px;
            margin-top: 15px;
        }
        
        .backend-option {
            padding: 20px;
            border: 2px solid #e9ecef;
            border-radius: 10px;
            background: white;
            cursor: pointer;
            transition: all 0.3s ease;
        }
        
        .backend-option:hover {
            border-color: #007bff;
            transform: translateY(-2px);
        }
        
        .backend-option.active {
            border-color: #007bff;
            background: #f0f8ff;
        }
        
        .backend-option h3 {
            color: #333;
            margin-bottom: 10px;
        }
        
        .backend-option p {
            color: #666;
            font-size: 14px;
            margin-bottom: 15px;
        }
        
        .backend-option .features {
            font-size: 12px;
            color: #28a745;
        }
        
        .server-config {
            margin-top: 15px;
            display: none;
        }
        
        .server-config.show {
            display: block;
        }
        
        .api-input-group {
            display: flex;
            gap: 10px;
            margin-top: 10px;
        }
        
        .api-input-group input {
            flex: 1;
            padding: 10px;
            border: 1px solid #ddd;
            border-radius: 5px;
        }
        
        .api-input-group button {
            padding: 10px 20px;
            background: #007bff;
            color: white;
            border: none;
            border-radius: 5px;
            cursor: pointer;
        }
        
        .status {
            padding: 15px 20px;
            font-weight: 500;
            text-align: center;
            transition: all 0.3s ease;
        }
        
        .status.loading {
            background: #fff3cd;
            color: #856404;
        }
        
        .status.ready {
            background: #d4edda;
            color: #155724;
        }
        
        .status.error {
            background: #f8d7da;
            color: #721c24;
        }
        
        .chat-container {
            height: 500px;
            display: flex;
            flex-direction: column;
            display: none;
        }
        
        .chat-container.show {
            display: flex;
        }
        
        .messages {
            flex: 1;
            padding: 20px;
            overflow-y: auto;
            background: #f8f9fa;
        }
        
        .message {
            margin: 15px 0;
            padding: 15px 20px;
            border-radius: 20px;
            max-width: 80%;
            word-wrap: break-word;
            animation: fadeIn 0.3s ease-in;
        }
        
        .user-message {
            background: #007bff;
            color: white;
            margin-left: auto;
            text-align: right;
        }
        
        .ai-message {
            background: #e9ecef;
            color: #333;
        }
        
        .system-message {
            background: #fff3cd;
            color: #856404;
            text-align: center;
            margin: 10px auto;
            font-style: italic;
        }
        
        .input-section {
            padding: 20px;
            background: white;
            border-top: 1px solid #e9ecef;
        }
        
        .input-container {
            display: flex;
            gap: 10px;
            align-items: center;
        }
        
        .message-input {
            flex: 1;
            padding: 15px;
            border: 2px solid #e9ecef;
            border-radius: 25px;
            font-size: 16px;
            outline: none;
            transition: border-color 0.3s ease;
        }
        
        .message-input:focus {
            border-color: #007bff;
        }
        
        .send-button {
            padding: 15px 25px;
            background: #007bff;
            color: white;
            border: none;
            border-radius: 25px;
            cursor: pointer;
            font-weight: 500;
            transition: background-color 0.3s ease;
        }
        
        .send-button:hover:not(:disabled) {
            background: #0056b3;
        }
        
        .send-button:disabled {
            background: #6c757d;
            cursor: not-allowed;
        }
        
        .loading {
            display: none;
            text-align: center;
            padding: 20px;
            color: #007bff;
        }
        
        .loading.show {
            display: block;
        }
        
        .spinner {
            display: inline-block;
            width: 20px;
            height: 20px;
            border: 3px solid #f3f3f3;
            border-top: 3px solid #007bff;
            border-radius: 50%;
            animation: spin 1s linear infinite;
            margin-right: 10px;
        }
        
        .quick-actions {
            display: flex;
            gap: 10px;
            margin-bottom: 15px;
            flex-wrap: wrap;
        }
        
        .quick-button {
            padding: 8px 15px;
            background: #f8f9fa;
            border: 1px solid #dee2e6;
            border-radius: 20px;
            cursor: pointer;
            font-size: 14px;
            transition: all 0.3s ease;
        }
        
        .quick-button:hover {
            background: #e9ecef;
            border-color: #adb5bd;
        }
        
        @keyframes fadeIn {
            from { opacity: 0; transform: translateY(10px); }
            to { opacity: 1; transform: translateY(0); }
        }
        
        @keyframes spin {
            0% { transform: rotate(0deg); }
            100% { transform: rotate(360deg); }
        }
        
        @media (max-width: 768px) {
            .backend-options {
                grid-template-columns: 1fr;
            }
            
            .container {
                margin: 10px;
                border-radius: 10px;
            }
            
            .header h1 {
                font-size: 2em;
            }
            
            .quick-actions {
                justify-content: center;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>ü§ñ Personal Language Model</h1>
            <p>Choose how you want to run your AI assistant</p>
        </div>
        
        <div class="backend-selector">
            <h2>Select Backend Type</h2>
            <div class="backend-options">
                <div class="backend-option" id="client-option" onclick="selectBackend('client')">
                    <h3>üåê Browser AI</h3>
                    <p>Run the AI model directly in your browser using WebAssembly</p>
                    <div class="features">‚úì No server needed ‚úì Always available ‚úì Privacy-focused</div>
                </div>
                
                <div class="backend-option" id="server-option" onclick="selectBackend('server')">
                    <h3>‚òÅÔ∏è Server API</h3>
                    <p>Connect to your deployed API server (Vercel, Replit, etc.)</p>
                    <div class="features">‚úì More powerful ‚úì Faster training ‚úì Persistent models</div>
                    <div class="server-config" id="server-config">
                        <div class="api-input-group">
                            <input type="text" id="api-url" placeholder="https://your-api-url.com" 
                                   value="https://personallanguagemodel.imreallyadi.repl.co">
                            <button onclick="testConnection()">Test</button>
                        </div>
                        <div id="connection-status"></div>
                    </div>
                </div>
            </div>
        </div>
        
        <div class="status" id="status">Select a backend option above to get started</div>
        
        <div class="chat-container" id="chat-container">
            <div class="messages" id="messages">
                <div class="ai-message message">
                    Welcome! I'm ready to chat. Ask me anything!
                </div>
            </div>
            
            <div class="loading" id="loading">
                <div class="spinner"></div>
                Generating response...
            </div>
            
            <div class="input-section">
                <div class="quick-actions">
                    <div class="quick-button" onclick="sendQuickMessage('Hello!')">üëã Say Hello</div>
                    <div class="quick-button" onclick="sendQuickMessage('What can you help me with?')">‚ùì Ask for Help</div>
                    <div class="quick-button" onclick="sendQuickMessage('Tell me about AI')">üß† About AI</div>
                    <div class="quick-button" onclick="clearChat()">üóëÔ∏è Clear Chat</div>
                </div>
                
                <div class="input-container">
                    <input 
                        type="text" 
                        id="messageInput" 
                        class="message-input" 
                        placeholder="Type your message here..."
                        onkeypress="handleKeyPress(event)"
                        disabled
                    >
                    <button id="sendButton" class="send-button" onclick="sendMessage()" disabled>Send</button>
                </div>
            </div>
        </div>
    </div>

    <script>
        let currentBackend = null;
        let pyodide = null;
        let API_BASE = null;
        let isModelReady = false;
        
        // Backend selection
        function selectBackend(type) {
            currentBackend = type;
            
            // Update UI
            document.querySelectorAll('.backend-option').forEach(opt => opt.classList.remove('active'));
            document.getElementById(`${type}-option`).classList.add('active');
            
            if (type === 'client') {
                document.getElementById('server-config').classList.remove('show');
                initializeClientSide();
            } else {
                document.getElementById('server-config').classList.add('show');
                API_BASE = document.getElementById('api-url').value;
                testConnection();
            }
        }
        
        // Client-side WebAssembly initialization
        async function initializeClientSide() {
            updateStatus("Loading Python environment...", "loading");
            
            try {
                pyodide = await loadPyodide();
                
                await pyodide.loadPackage(['micropip']);
                await pyodide.runPython(`
                    import micropip
                    await micropip.install(['torch', 'numpy'])
                `);
                
                // Load model code
                await pyodide.runPython(`
                    import torch
                    import torch.nn as nn
                    import numpy as np
                    import random
                    
                    current_model = None
                    char_to_idx = None
                    idx_to_char = None
                    
                    class SimpleTransformer(nn.Module):
                        def __init__(self, vocab_size, embed_dim=32, num_heads=2, num_layers=1, sequence_length=15):
                            super().__init__()
                            self.embed_dim = embed_dim
                            self.sequence_length = sequence_length
                            
                            self.embedding = nn.Embedding(vocab_size, embed_dim)
                            self.pos_encoding = nn.Parameter(torch.randn(sequence_length, embed_dim))
                            
                            encoder_layer = nn.TransformerEncoderLayer(
                                d_model=embed_dim, nhead=num_heads, dim_feedforward=embed_dim * 2,
                                dropout=0.0, batch_first=True
                            )
                            self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)
                            self.output_layer = nn.Linear(embed_dim, vocab_size)
                        
                        def forward(self, src):
                            seq_len = src.size(1)
                            embeddings = self.embedding(src)
                            embeddings += self.pos_encoding[:seq_len].unsqueeze(0)
                            
                            mask = torch.triu(torch.ones(seq_len, seq_len)) == 1
                            mask = mask.transpose(0, 1).float()
                            mask = mask.masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, 0.0)
                            
                            output = self.transformer(embeddings, mask=mask)
                            return self.output_layer(output)
                    
                    def train_demo_model():
                        global current_model, char_to_idx, idx_to_char
                        
                        demo_text = "Hello I am an AI assistant. I can help with questions and conversations. I enjoy talking about science technology history arts and life. I aim to provide helpful responses. What would you like to talk about? I can help with explanations writing problem solving and conversation. Thank you for chatting! How can I help you today? I hope you are having a great day. Feel free to ask me anything. I love learning and sharing knowledge."
                        
                        chars = sorted(list(set(demo_text)))
                        char_to_idx = {ch: i for i, ch in enumerate(chars)}
                        idx_to_char = {i: ch for i, ch in enumerate(chars)}
                        
                        encoded_text = [char_to_idx[ch] for ch in demo_text]
                        
                        model = SimpleTransformer(vocab_size=len(char_to_idx))
                        optimizer = torch.optim.Adam(model.parameters(), lr=0.01)
                        
                        sequence_length = 15
                        for epoch in range(3):
                            for i in range(0, len(encoded_text) - sequence_length, sequence_length):
                                if i + sequence_length + 1 >= len(encoded_text):
                                    break
                                
                                inputs = torch.tensor([encoded_text[i:i+sequence_length]], dtype=torch.long)
                                targets = torch.tensor([encoded_text[i+1:i+sequence_length+1]], dtype=torch.long)
                                
                                optimizer.zero_grad()
                                outputs = model(inputs)
                                loss = nn.CrossEntropyLoss()(outputs.view(-1, outputs.size(-1)), targets.view(-1))
                                loss.backward()
                                optimizer.step()
                        
                        current_model = model
                        return True
                    
                    def generate_response(prompt, max_length=50):
                        global current_model, char_to_idx, idx_to_char
                        
                        if current_model is None:
                            return "Model not ready"
                        
                        current_model.eval()
                        with torch.no_grad():
                            context = [char_to_idx.get(ch, 0) for ch in prompt]
                            
                            for _ in range(max_length):
                                if len(context) > current_model.sequence_length:
                                    context = context[-current_model.sequence_length:]
                                
                                input_tensor = torch.tensor([context], dtype=torch.long)
                                outputs = current_model(input_tensor)
                                logits = outputs[0, -1, :] / 0.8
                                
                                probs = torch.softmax(logits, dim=-1)
                                next_token = torch.multinomial(probs, 1).item()
                                context.append(next_token)
                            
                            return ''.join([idx_to_char.get(idx, '') for idx in context])
                `);
                
                updateStatus("Training model...", "loading");
                await pyodide.runPython(`train_demo_model()`);
                
                updateStatus("AI model ready!", "ready");
                enableChat();
                isModelReady = true;
                
            } catch (error) {
                updateStatus("Failed to load AI model: " + error.message, "error");
                console.error("Client-side error:", error);
            }
        }
        
        // Server-side API connection
        async function testConnection() {
            const apiUrl = document.getElementById('api-url').value.trim();
            if (!apiUrl) {
                updateStatus("Please enter an API URL", "error");
                return;
            }
            
            API_BASE = apiUrl;
            updateStatus("Testing connection...", "loading");
            
            try {
                const response = await fetch(`${API_BASE}/model/info`);
                if (response.ok) {
                    const info = await response.json();
                    updateStatus("Connected to server API!", "ready");
                    enableChat();
                    isModelReady = true;
                    document.getElementById('connection-status').innerHTML = 
                        `<small style="color: green;">‚úì Connected - ${info.total_parameters || 0} parameters</small>`;
                } else {
                    throw new Error(`HTTP ${response.status}`);
                }
            } catch (error) {
                updateStatus("Connection failed: " + error.message, "error");
                document.getElementById('connection-status').innerHTML = 
                    `<small style="color: red;">‚úó Connection failed</small>`;
            }
        }
        
        // UI helper functions
        function updateStatus(message, type) {
            const status = document.getElementById('status');
            status.textContent = message;
            status.className = `status ${type}`;
        }
        
        function enableChat() {
            document.getElementById('chat-container').classList.add('show');
            document.getElementById('messageInput').disabled = false;
            document.getElementById('sendButton').disabled = false;
        }
        
        function addMessage(content, isUser = false, isSystem = false) {
            const messagesDiv = document.getElementById('messages');
            const messageDiv = document.createElement('div');
            
            if (isSystem) {
                messageDiv.className = 'message system-message';
            } else {
                messageDiv.className = `message ${isUser ? 'user-message' : 'ai-message'}`;
            }
            
            messageDiv.textContent = content;
            messagesDiv.appendChild(messageDiv);
            messagesDiv.scrollTop = messagesDiv.scrollHeight;
        }
        
        function setLoading(loading) {
            document.getElementById('loading').classList.toggle('show', loading);
            document.getElementById('sendButton').disabled = loading;
            document.getElementById('messageInput').disabled = loading;
        }
        
        // Chat functions
        async function sendMessage(message = null) {
            const input = document.getElementById('messageInput');
            const text = message || input.value.trim();
            
            if (!text || !isModelReady) return;
            
            addMessage(text, true);
            if (!message) input.value = '';
            
            setLoading(true);
            
            try {
                let response;
                
                if (currentBackend === 'client') {
                    // Client-side generation
                    const prompt = `User: ${text}\nAI:`;
                    const generated = await pyodide.runPython(`generate_response("${prompt.replace(/"/g, '\\"')}", 40)`);
                    
                    let aiResponse = generated;
                    if (aiResponse.includes('AI:')) {
                        aiResponse = aiResponse.split('AI:').pop().trim();
                    }
                    aiResponse = aiResponse.replace(/User:.*$/g, '').trim();
                    
                    addMessage(aiResponse || "I'm still learning!");
                    
                } else {
                    // Server-side generation
                    const cleanText = text.replace(/[^a-zA-Z0-9\s?!.,-]/g, '');
                    const apiResponse = await fetch(`${API_BASE}/api/chat/${encodeURIComponent(cleanText)}`);
                    
                    if (!apiResponse.ok) throw new Error(`HTTP ${apiResponse.status}`);
                    
                    const data = await apiResponse.json();
                    if (data.error) {
                        addMessage(`Error: ${data.error}`, false, true);
                    } else {
                        addMessage(data.response || 'No response received');
                    }
                }
                
            } catch (error) {
                console.error('Chat error:', error);
                addMessage('Sorry, I encountered an error. Please try again.', false, true);
            }
            
            setLoading(false);
        }
        
        function sendQuickMessage(message) {
            sendMessage(message);
        }
        
        function clearChat() {
            document.getElementById('messages').innerHTML = `
                <div class="ai-message message">
                    Chat cleared! How can I help you today?
                </div>
            `;
        }
        
        function handleKeyPress(event) {
            if (event.key === 'Enter') {
                sendMessage();
            }
        }
        
        // Auto-detect API URL on page load
        document.addEventListener('DOMContentLoaded', function() {
            if (window.location.hostname.includes('github.io')) {
                // Running on GitHub Pages, default to server mode
                selectBackend('server');
            }
        });
    </script>
</body>
</html>